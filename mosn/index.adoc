= service mesh 乱谈

== 为什么需要 sidecar

稍微大一点的公司，不管架构图画的多好看，内部可能都是下面这样的现状：

image::why_sm.png[大公司的系统现状]

如果想在公司内新做一套配置推送系统，本来只需要做一遍的 sdk 工作就会需要乘以语言数量：

image::why_sm-clientspng.png[]

程序员也不傻，总还是有解决办法的：

image::sidecar.png[]

出自 《Designing Distributed Systems》。

image::sidecar2.jpeg[]

狗坐的位置就是 sidecar(笑

image::sidecar3.png[]

总之，我们把自己的工作的大头集中在了 sidecar 里，SDK 的工作虽没有完全省掉，但已被极大简化，只剩下比如：

* 读取文件，替换内存中的 map
* 向本地的 sidecar 发一个 http 请求。

是在一个面试的时间内就能完成的代码。热更新相关的知识：

* 无锁双 buffer
* fsnotify

== 为什么需要 mesh

image::ratelimit.png[]

image::circuitbreaker.png[]

image::lb.png[]

嗯，你说为什么呢？

[quote, https://jimmysong.io/blog/what-is-a-service-mesh/]
____
服务网格（Service Mesh）是处理服务间通信的基础设施层。它负责构成现代云原生应用程序的复杂服务拓扑来可靠地交付请求。在实践中，Service Mesh 通常以轻量级网络代理阵列的形式实现，这些代理与应用程序代码部署在一起，对应用程序来说无需感知代理的存在。
____

TODO，这里有图，circuit breaker，ratelimit 模块本来在 web 框架中 => 这些功能被迁移到了 service mesh 中。

从工程角度来讲，下沉的好处：

* 语言相关的轮子变成了语言无关的公共轮
* 业务团队忙业务，基础社区团队忙基础设施，模块解耦，分工细化
* 不用求你的客户来升级了，自己就能搞定。爸爸变回了同事。

== mesh 的麻烦

=== 协议太多

就像 RPC 框架万年统一不了一样，一个公共的流量层就需要去对接五花八门的各种协议：

* HTTP
* HTTP/2
* HTTP/3
* dubbo
* sofarpc
* gRPC
* thrift

如果一个公司内存在多种 RPC 协议，可能会比较痛苦。但我们可以给我们认识的协议简单分个类。根据协议的交互方式，可以分为 pingpong，和 multiplex 两种类型。

====  pingpong

请求发送完毕后，需要阻塞等待响应。一个请求的响应处理完才能发送下一个请求。典型的比如：

* HTTP
* redis 协议
* MySQL 协议

====  multiplex

=== 政治问题

OUC 基金会，伪开源。

从不好的方面来讲，很多公司所谓的借助社区力量，其实就是把大家当成不要钱的外包员工。

当然，我们可以换一个说法，如果你给一家公司的开源项目贡献了大量的代码，是有机会通过这个过程直接进入这家公司工作的。
